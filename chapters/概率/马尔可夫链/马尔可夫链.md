# 马尔可夫链

> 注明:
>  
- 首先给定每一个action后面的相关action的概率，然后随机重复无限次action链条后，会发现统计下的每一个action后面的相关action的概率都无限等同于给定的每一个action后面的相关action的概率。这样就可以发现每一个action后面的相关action的概率与前面的action无关。（非常重要的实验，要分很多种情况，并且每一种情况要做很多次实验）（一开始手动做实验，理论掌握后可以用机器来算）。
- 这样就可以推断出我们首先要统计得出每一个action后面的相关action的概率。这个工作一开始手动统计，理论掌握后可以用机器来统计。计算语言学是一个非常好的例子，而且和nlp和语文学习都有强关联。

## 经典实例

- 从一个城市去周围的城市的概率（harvardX例子和Youtube例子）
- 股票牛市和熊市的例子
- 阴天晴天的例子
- 早餐的例子
- 锤子剪刀布的例子

## 开始做

![](/images/概率/马尔可夫链/马尔可夫链/1a.jpg)

## 参考文献及资料

1. 维基百科
	- [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) | [马尔可夫链](https://zh.wikipedia.org/wiki/马尔可夫链) 
	- [Andrey Markov](https://en.wikipedia.org/wiki/Andrey_Markov) | [安德烈·马尔可夫](https://zh.wikipedia.org/wiki/安德烈·马尔可夫) 

2. [Markov chain exploration](https://www.khanacademy.org/computing/computer-science/informationtheory/moderninfotheory/pi/markov-chain-exploration)
3. [Markov Chains - Setosa](https://setosa.io/markov/#%7B%22tm%22%3A%5B%5B0.9%2C0.1%5D%2C%5B0.1%2C0.9%5D%5D%7D)
4. [Markov Chain Simulator](http://markov.yoriz.co.uk)